{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import math\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from azureml.core import Workspace, Dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def add_fourier_features(df, column_name, period, n, period_name = \"f\"):\r\n",
    "    t = df[column_name]\r\n",
    "    for i in range(n):\r\n",
    "        j = math.ceil((i+1)/2)\r\n",
    "        if i%2:\r\n",
    "            df[f'{period_name}_{i}'] = np.cos(j * 2 * np.pi * t / period)\r\n",
    "        else:\r\n",
    "            df[f'{period_name}_{i}'] = np.sin(j * 2 * np.pi * t / period)\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def create_workday_weekend_features(df, fourier_order):\r\n",
    "    # split features in workday / weekend\r\n",
    "    df['is_workday'] = (~(df.is_holiday.astype(bool) | (df.day_of_week == 5) | (df.day_of_week == 6)))\r\n",
    "    workday_data = {\r\n",
    "        f'workday_{k}':df[k]*df.is_workday.astype(int)\r\n",
    "        for k\r\n",
    "        in ['temperature', 'solar_ghi'] + [f'f_quarter_{f}' for f in range(fourier_order)]\r\n",
    "    }\r\n",
    "    weekend_data = {\r\n",
    "        f'weekend_{k}':df[k]*(~df.is_workday).astype(int)\r\n",
    "        for k\r\n",
    "        in ['temperature', 'solar_ghi'] + [f'f_quarter_{f}' for f in range(fourier_order)]\r\n",
    "    }\r\n",
    "    return workday_data, weekend_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "WORKDIR = os.getcwd()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Create a folder\r\n",
    "BATCH_FOLDER = 'batch-data'\r\n",
    "os.makedirs(BATCH_FOLDER, exist_ok=True)\r\n",
    "print(\"Folder created!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Folder created!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# get the workspace from config.json\r\n",
    "ws = Workspace.from_config()\r\n",
    "# get the datastore to upload our data\r\n",
    "datastore = ws.get_default_datastore()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# retrieve test dataset from Azure Datastore\r\n",
    "ds = Dataset.get_by_name(ws, name=\"energy_data_15_min\")\r\n",
    "df = ds.to_pandas_dataframe()\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          data_index_  temperature  solar_ghi  solar_prediction_mw  \\\n",
       "0 2020-01-01 00:00:00   274.989655        0.0                  0.0   \n",
       "1 2020-01-01 00:15:00   274.925659        0.0                  0.0   \n",
       "2 2020-01-01 00:30:00   274.861694        0.0                  0.0   \n",
       "3 2020-01-01 00:45:00   274.797699        0.0                  0.0   \n",
       "4 2020-01-01 01:00:00   274.423157        0.0                  0.0   \n",
       "\n",
       "   wind_prediction_mw  load_actuals_mw  \n",
       "0           70.865426        95.756328  \n",
       "1           69.296785        94.836196  \n",
       "2           66.977409        93.798127  \n",
       "3           64.305715        92.162902  \n",
       "4           61.128262        91.506670  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_index_</th>\n",
       "      <th>temperature</th>\n",
       "      <th>solar_ghi</th>\n",
       "      <th>solar_prediction_mw</th>\n",
       "      <th>wind_prediction_mw</th>\n",
       "      <th>load_actuals_mw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>274.989655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.865426</td>\n",
       "      <td>95.756328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:15:00</td>\n",
       "      <td>274.925659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.296785</td>\n",
       "      <td>94.836196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 00:30:00</td>\n",
       "      <td>274.861694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.977409</td>\n",
       "      <td>93.798127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 00:45:00</td>\n",
       "      <td>274.797699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.305715</td>\n",
       "      <td>92.162902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>274.423157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.128262</td>\n",
       "      <td>91.506670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# pick up last week, drop target and convert to numpy array\r\n",
    "X = df.iloc[-7:]\r\n",
    "X = X.drop(['load_actuals_mw'], axis=1)\r\n",
    "# generate additional ML features\r\n",
    "X['day_of_week'] = X['data_index_'].dt.dayofweek\r\n",
    "X['quarter_of_day'] =  np.where(X['data_index_'].dt.hour > 0, X['data_index_'].dt.hour.apply(lambda x: math.ceil(x / 6.)), 4)\r\n",
    "\r\n",
    "# holiday indicator feature\r\n",
    "from workalendar.europe import Netherlands\r\n",
    "cal = Netherlands(include_carnival=True)\r\n",
    "\r\n",
    "# Make a pandas series with holidays of interest\r\n",
    "holidates = cal.holidays(2020) + cal.holidays(2021)\r\n",
    "pd_holidays = pd.to_datetime([d[0] for d in holidates])\r\n",
    "\r\n",
    "X['is_holiday'] = pd.to_datetime(X['data_index_'].dt.date).isin(pd_holidays)\r\n",
    "\r\n",
    "# add Fourier features to capture daily pattern in model\r\n",
    "fourier_order = 6\r\n",
    "\r\n",
    "X = add_fourier_features(X, \"quarter_of_day\", 4 * 24, fourier_order, \"f_quarter\")\r\n",
    "\r\n",
    "# split workdays and weekend/holidays\r\n",
    "workday_data, weekend_data = create_workday_weekend_features(X, fourier_order)\r\n",
    "X_linregr = pd.DataFrame(\r\n",
    "    {**workday_data, **weekend_data}\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# List the input feature columns\r\n",
    "feat_columns = list(workday_data.keys()) + list(weekend_data.keys())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "X = X_linregr[feat_columns].to_numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Save each sample as a separate file\r\n",
    "print(\"Saving files...\")\r\n",
    "for i in range(len(X)):\r\n",
    "    fname = str(i+1) + '.csv'\r\n",
    "    X[i].tofile(os.path.join(BATCH_FOLDER, fname), sep=\",\")\r\n",
    "print(\"files saved!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving files...\n",
      "files saved!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "datastore.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Uploading an estimated of 7 files\n",
      "Uploading batch-data\\1.csv\n",
      "Uploaded batch-data\\1.csv, 1 files out of an estimated total of 7\n",
      "Uploading batch-data\\2.csv\n",
      "Uploaded batch-data\\2.csv, 2 files out of an estimated total of 7\n",
      "Uploading batch-data\\3.csv\n",
      "Uploaded batch-data\\3.csv, 3 files out of an estimated total of 7\n",
      "Uploading batch-data\\4.csv\n",
      "Uploaded batch-data\\4.csv, 4 files out of an estimated total of 7\n",
      "Uploading batch-data\\5.csv\n",
      "Uploaded batch-data\\5.csv, 5 files out of an estimated total of 7\n",
      "Uploading batch-data\\6.csv\n",
      "Uploaded batch-data\\6.csv, 6 files out of an estimated total of 7\n",
      "Uploading batch-data\\7.csv\n",
      "Uploaded batch-data\\7.csv, 7 files out of an estimated total of 7\n",
      "Uploaded 7 files\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_f0ee28efb8c54513b8a85695db09d576"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Register a dataset for the input data\r\n",
    "batch_data_set = Dataset.File.from_files(path=(datastore, 'batch-data/'), validate=False)\r\n",
    "try:\r\n",
    "    batch_data_set = batch_data_set.register(workspace=ws, \r\n",
    "                                             name='batch-data',\r\n",
    "                                             description='batch data for pytown demand energy forecast',\r\n",
    "                                             create_new_version=True)\r\n",
    "except Exception as ex:\r\n",
    "    print(ex)\r\n",
    "\r\n",
    "print(\"Done!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0c0641573e26ff90e279ea3d930a41116c682b71b3d26a209012b19edb32094"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mlops': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}