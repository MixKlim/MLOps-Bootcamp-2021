{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create batch pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Connect to your workspace\r\n",
    "from azureml.core import Workspace\r\n",
    "ws = Workspace.from_config()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Provision inference compute"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
    "from azureml.core.compute_target import ComputeTargetException\r\n",
    "\r\n",
    "cluster_name = \"mlopsbootcamp\"\r\n",
    "\r\n",
    "try:\r\n",
    "    # Check for existing compute target\r\n",
    "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
    "    print('Found existing cluster, use it.')\r\n",
    "except ComputeTargetException:\r\n",
    "    # If it doesn't already exist, create it\r\n",
    "    try:\r\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS2_v2', max_nodes=2)\r\n",
    "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
    "        inference_cluster.wait_for_completion(show_output=True)\r\n",
    "    except Exception as ex:\r\n",
    "        print(ex)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating......\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a pipeline for batch inferencing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\r\n",
    "# Create a folder for the experiment files\r\n",
    "experiment_folder = 'batch_pipeline'\r\n",
    "os.makedirs(experiment_folder, exist_ok=True)\r\n",
    "\r\n",
    "print(experiment_folder)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch_pipeline\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get path to the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from azureml.core import Model\r\n",
    "model_list = Model.list(ws)\r\n",
    "model_path = Model.get_model_path('fourier_regression', _workspace=ws)\r\n",
    "print(model_list, model_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Model(workspace=Workspace.create(name='mlopsworkspace', subscription_id='e7d71274-b7c4-47ed-9751-2505b563b918', resource_group='mlopsgroup'), name=fourier_regression, id=fourier_regression:1, version=1, tags={}, properties={})] azureml-models\\fourier_regression\\1\\fourier.pkl\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import joblib\r\n",
    "model = joblib.load(model_path)\r\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check the batch data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "mini_batch = list()\r\n",
    "for (dirpath, dirnames, filenames) in os.walk(\"batch-data\"):\r\n",
    "    mini_batch += [os.path.join(dirpath, file) for file in filenames]\r\n",
    "for elem in mini_batch:\r\n",
    "    print(elem)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch-data\\1.csv\n",
      "batch-data\\2.csv\n",
      "batch-data\\3.csv\n",
      "batch-data\\4.csv\n",
      "batch-data\\5.csv\n",
      "batch-data\\6.csv\n",
      "batch-data\\7.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make prediction per batch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\r\n",
    "def run(mini_batch):\r\n",
    "    # This runs for each batch\r\n",
    "    resultList = []\r\n",
    "\r\n",
    "    # process each file in the batch\r\n",
    "    for f in mini_batch:\r\n",
    "        # Read comma-delimited data into an array\r\n",
    "        data = np.genfromtxt(f, delimiter=',')\r\n",
    "        print(data)\r\n",
    "        # Reshape into a 2-dimensional array for model input\r\n",
    "        prediction = model.predict(data.reshape(1, -1))\r\n",
    "        # Append prediction to results\r\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\r\n",
    "    return resultList\r\n",
    "\r\n",
    "result = run(mini_batch)\r\n",
    "result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summarize into python script"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "%%writefile $experiment_folder\\score.py\r\n",
    "\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "from azureml.core import Model\r\n",
    "import joblib\r\n",
    "\r\n",
    "def init():\r\n",
    "    # Runs when the pipeline step is initialized\r\n",
    "    global model\r\n",
    "\r\n",
    "    # load the model\r\n",
    "    model_path = Model.get_model_path('fourier_regression')\r\n",
    "    model = joblib.load(model_path)\r\n",
    "\r\n",
    "def run(mini_batch):\r\n",
    "    # This runs for each batch\r\n",
    "    resultList = []\r\n",
    "\r\n",
    "    # process each file in the batch\r\n",
    "    for f in mini_batch:\r\n",
    "        # Read comma-delimited data into an array\r\n",
    "        data = np.genfromtxt(f, delimiter=',')\r\n",
    "        # Reshape into a 2-dimensional array for model input\r\n",
    "        prediction = model.predict(data.reshape(1, -1))\r\n",
    "        # Append prediction to results\r\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\r\n",
    "    return resultList"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting batch_pipeline\\score.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create conda environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "%%writefile $experiment_folder\\batch_environment.yml\r\n",
    "name: batch_environment\r\n",
    "dependencies:\r\n",
    "- python=3.8\r\n",
    "- numpy\r\n",
    "- pandas\r\n",
    "- scikit-learn\r\n",
    "- pip:\r\n",
    "    - azureml-core\r\n",
    "    - azureml-dataset-runtime[fuse]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting batch_pipeline\\batch_environment.yml\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define run using environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from azureml.core import Environment\r\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
    "\r\n",
    "# Create an Environment for the experiment\r\n",
    "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_environment.yml\")\r\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
    "print('Configuration ready.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configure batch pipeline steps"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from datetime import datetime\r\n",
    "\r\n",
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\r\n",
    "from azureml.data import OutputFileDatasetConfig\r\n",
    "from azureml.core.runconfig import DockerConfiguration\r\n",
    "\r\n",
    "# Get the batch dataset for input\r\n",
    "batch_data_set = ws.datasets['batch-data']\r\n",
    "\r\n",
    "# Set the output location\r\n",
    "default_ds = ws.get_default_datastore()\r\n",
    "output_dir = OutputFileDatasetConfig(name='inferences')\r\n",
    "\r\n",
    "# Define the parallel run step step configuration\r\n",
    "parallel_run_config = ParallelRunConfig(\r\n",
    "    source_directory=experiment_folder,\r\n",
    "    entry_script=\"score.py\",\r\n",
    "    mini_batch_size=\"5\",\r\n",
    "    error_threshold=10,\r\n",
    "    output_action=\"append_row\",\r\n",
    "    environment=batch_env,\r\n",
    "    compute_target=inference_cluster,\r\n",
    "    node_count=2)\r\n",
    "\r\n",
    "parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\r\n",
    "\r\n",
    "# Create the parallel run step\r\n",
    "parallelrun_step = ParallelRunStep(\r\n",
    "    name=parallel_step_name,\r\n",
    "    parallel_run_config=parallel_run_config,\r\n",
    "    inputs=[batch_data_set.as_named_input('batch_data')],\r\n",
    "    output=output_dir,\r\n",
    "    arguments=[],\r\n",
    "    allow_reuse=True\r\n",
    ")\r\n",
    "\r\n",
    "print('Steps defined')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Steps defined\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "from azureml.core import Experiment\r\n",
    "from azureml.pipeline.core import Pipeline\r\n",
    "\r\n",
    "# Create the pipeline\r\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\r\n",
    "\r\n",
    "# Run the pipeline as an experiment\r\n",
    "pipeline_run = Experiment(ws, 'pytown-energy-demand-batch').submit(pipeline)\r\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created step batchscoring-202107311955 [f431e354][591b0fbb-7303-48d3-a748-32bfa9cd5f1d], (This step is eligible to reuse a previous run's output)\n",
      "Submitted PipelineRun b7f54fc5-eb51-44cf-8a51-8290e746fcd6\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/b7f54fc5-eb51-44cf-8a51-8290e746fcd6?wsid=/subscriptions/e7d71274-b7c4-47ed-9751-2505b563b918/resourcegroups/mlopsgroup/workspaces/mlopsworkspace&tid=a0f1cacd-618c-4403-b945-76fb3d6874e5\n",
      "PipelineRunId: b7f54fc5-eb51-44cf-8a51-8290e746fcd6\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/b7f54fc5-eb51-44cf-8a51-8290e746fcd6?wsid=/subscriptions/e7d71274-b7c4-47ed-9751-2505b563b918/resourcegroups/mlopsgroup/workspaces/mlopsworkspace&tid=a0f1cacd-618c-4403-b945-76fb3d6874e5\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'b7f54fc5-eb51-44cf-8a51-8290e746fcd6', 'status': 'Completed', 'startTimeUtc': '2021-07-31T18:58:14.199303Z', 'endTimeUtc': '2021-07-31T18:58:17.093958Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlopsworkspace0185046391.blob.core.windows.net/azureml/ExperimentRun/dcid.b7f54fc5-eb51-44cf-8a51-8290e746fcd6/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=Z3aqNhUQKYXFQ0Kog9NiqDaww9Q2A%2BxsW61BnMRmQcA%3D&st=2021-07-31T18%3A48%3A17Z&se=2021-08-01T02%3A58%3A17Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopsworkspace0185046391.blob.core.windows.net/azureml/ExperimentRun/dcid.b7f54fc5-eb51-44cf-8a51-8290e746fcd6/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=AiM3IC6lAlobwji%2BeSczSxGz%2FspL1ntTZb1JHKsWs8c%3D&st=2021-07-31T18%3A48%3A18Z&se=2021-08-01T02%3A58%3A18Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopsworkspace0185046391.blob.core.windows.net/azureml/ExperimentRun/dcid.b7f54fc5-eb51-44cf-8a51-8290e746fcd6/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=b2Om5PrLzRdl28F8qAEDsvc6lDvbE5S5gXz5kztflOw%3D&st=2021-07-31T18%3A48%3A18Z&se=2021-08-01T02%3A58%3A18Z&sp=r'}, 'submittedBy': 'Iemke Steunebrink'}\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Run' object has no attribute 'get_output_data'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-967ae966ac5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Get the run for the first step and download its output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprediction_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprediction_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inferences'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprediction_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'batch-results'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Run' object has no attribute 'get_output_data'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Retrieve predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "import pandas as pd\r\n",
    "import shutil\r\n",
    "\r\n",
    "# Remove the local results folder if left over from a previous run\r\n",
    "shutil.rmtree('batch-results', ignore_errors=True)\r\n",
    "\r\n",
    "# Get the run for the first step and download its output\r\n",
    "prediction_run = next(pipeline_run.get_children())\r\n",
    "prediction_output = prediction_run.get_output_data('inferences')\r\n",
    "prediction_output.download(local_path='batch-results')\r\n",
    "\r\n",
    "# Traverse the folder hierarchy and find the results file\r\n",
    "for root, dirs, files in os.walk('batch-results'):\r\n",
    "    for file in files:\r\n",
    "        if file.endswith('parallel_run_step.txt'):\r\n",
    "            result_file = os.path.join(root,file)\r\n",
    "\r\n",
    "# cleanup output format\r\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
    "df.columns = [\"File\", \"Prediction\"]\r\n",
    "\r\n",
    "# Display the first 20 results\r\n",
    "df.head(20)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Run' object has no attribute 'get_output_data'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-e97664ae67e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Get the run for the first step and download its output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprediction_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprediction_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inferences'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprediction_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'batch-results'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Run' object has no attribute 'get_output_data'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Publish the pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(name='Fourier_regression_batch_prediction_pipeline',\r\n",
    "                                                   description='Batch scoring using linear regression model with Fourier ML features',\r\n",
    "                                                   version='1.0')\r\n",
    "\r\n",
    "published_pipeline"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(Name: Fourier_regression_batch_prediction_pipeline,\n",
       "Id: f2695278-3a6d-4542-ae2a-39537a7a3376,\n",
       "Status: Active,\n",
       "Endpoint: https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/e7d71274-b7c4-47ed-9751-2505b563b918/resourceGroups/mlopsgroup/providers/Microsoft.MachineLearningServices/workspaces/mlopsworkspace/PipelineRuns/PipelineSubmit/f2695278-3a6d-4542-ae2a-39537a7a3376)"
      ],
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Fourier_regression_batch_prediction_pipeline</td><td><a href=\"https://ml.azure.com/pipelines/f2695278-3a6d-4542-ae2a-39537a7a3376?wsid=/subscriptions/e7d71274-b7c4-47ed-9751-2505b563b918/resourcegroups/mlopsgroup/workspaces/mlopsworkspace\" target=\"_blank\" rel=\"noopener\">f2695278-3a6d-4542-ae2a-39537a7a3376</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/e7d71274-b7c4-47ed-9751-2505b563b918/resourceGroups/mlopsgroup/providers/Microsoft.MachineLearningServices/workspaces/mlopsworkspace/PipelineRuns/PipelineSubmit/f2695278-3a6d-4542-ae2a-39537a7a3376\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get REST endpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "rest_endpoint = published_pipeline.endpoint\r\n",
    "print(rest_endpoint)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/e7d71274-b7c4-47ed-9751-2505b563b918/resourceGroups/mlopsgroup/providers/Microsoft.MachineLearningServices/workspaces/mlopsworkspace/PipelineRuns/PipelineSubmit/f2695278-3a6d-4542-ae2a-39537a7a3376\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Schedule the pipeline to run every Monday at 04:00 in the morning (02:00 UTC)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from azureml.pipeline.core import ScheduleRecurrence, Schedule\r\n",
    "\r\n",
    "weekly = ScheduleRecurrence(frequency='Week', interval=1, week_days=[\"Monday\"], time_of_day=\"02:00\")\r\n",
    "pipeline_schedule = Schedule.create(ws, name='Weekly Predictions',\r\n",
    "                                        description='batch inferencing',\r\n",
    "                                        pipeline_id=published_pipeline.id,\r\n",
    "                                        experiment_name='Batch_Prediction',\r\n",
    "                                        recurrence=weekly)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Disable pipeline with active schedule"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "ss = Schedule.list(ws)\r\n",
    "for s in ss:\r\n",
    "    print(s)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(Name: Weekly Predictions,\n",
      "Id: e14c5ce5-db2c-462b-97f4-8c1c21faa31b,\n",
      "Status: Active,\n",
      "Pipeline Id: f2695278-3a6d-4542-ae2a-39537a7a3376,\n",
      "Pipeline Endpoint Id: None,\n",
      "Recurrence Details: Runs at 2:00 on Monday every Week)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "def stop_by_schedule_id(ws, schedule_id):\r\n",
    "    s = next(s for s in Schedule.list(ws) if s.id == schedule_id)\r\n",
    "    s.disable()\r\n",
    "    return s\r\n",
    "\r\n",
    "schedule_id = 'e14c5ce5-db2c-462b-97f4-8c1c21faa31b'\r\n",
    "stop_by_schedule_id(ws, schedule_id)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(Name: Weekly Predictions,\n",
       "Id: e14c5ce5-db2c-462b-97f4-8c1c21faa31b,\n",
       "Status: Disabled,\n",
       "Pipeline Id: f2695278-3a6d-4542-ae2a-39537a7a3376,\n",
       "Pipeline Endpoint Id: None,\n",
       "Recurrence Details: Runs at 2:00 on Monday every Week)"
      ],
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Pipeline Id</th><th>Pipeline Endpoint Id</th><th>Recurrence Details</th></tr><tr><td>Weekly Predictions</td><td>e14c5ce5-db2c-462b-97f4-8c1c21faa31b</td><td>Disabled</td><td><a href=\"https://ml.azure.com/pipelines/f2695278-3a6d-4542-ae2a-39537a7a3376?wsid=/subscriptions/e7d71274-b7c4-47ed-9751-2505b563b918/resourcegroups/mlopsgroup/workspaces/mlopsworkspace\" target=\"_blank\" rel=\"noopener\">f2695278-3a6d-4542-ae2a-39537a7a3376</a></td><td></td><td>Runs at 2:00 on Monday every Week</td></tr></table>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "961fe3d6e9ea56fa06fd73020a136aec184910a7ddbee69d542583f08a86105e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}